{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_epochs_target = 10\n",
    "num_epochs_shadow = 10\n",
    "num_epochs_attack = 20\n",
    "\n",
    "# NOTE: this code is only tested on CPU, there may be some issues on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "# define transform and load dataset\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_set = dsets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_set = TensorDataset(train_set.data, train_set.targets)\n",
    "test_set = dsets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "split_size = len(train_set) // 4\n",
    "\n",
    "data_train_shadow = Subset(train_set, range(0, split_size))\n",
    "data_out_shadow = Subset(train_set, range(split_size, split_size * 2))\n",
    "data_train_attack = Subset(train_set, range(0, split_size * 2))\n",
    "data_train_target = Subset(train_set, range(split_size * 2, split_size * 3))\n",
    "data_nonmember_target = Subset(train_set, range(split_size * 3, len(train_set)))\n",
    "data_eval_attack = Subset(train_set, range(split_size * 2, len(train_set)))\n",
    "\n",
    "\n",
    "# make sure the splitted dataset are transformed\n",
    "class TransformedTensorDataset(TensorDataset):\n",
    "    def __init__(self, data_tensor, target_tensor, transform=None):\n",
    "        assert data_tensor.size(0) == target_tensor.size(0)\n",
    "        self.data_tensor = data_tensor\n",
    "        self.target_tensor = target_tensor\n",
    "        self.transform = transform\n",
    "        self.tensors = (data_tensor, target_tensor)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data_tensor[index]\n",
    "        target = self.target_tensor[index]\n",
    "        data = Image.fromarray(data.numpy(), mode=\"L\")\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_tensor.size(0)\n",
    "\n",
    "\n",
    "def subset_to_tensor(subset):\n",
    "    return TransformedTensorDataset(\n",
    "        torch.stack([subset[i][0] for i in range(len(subset))]),\n",
    "        torch.tensor([subset[i][1] for i in range(len(subset))]),\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "\n",
    "data_train_shadow = subset_to_tensor(data_train_shadow)\n",
    "data_out_shadow = subset_to_tensor(data_out_shadow)\n",
    "data_train_attack = subset_to_tensor(data_train_attack)\n",
    "data_train_target = subset_to_tensor(data_train_target)\n",
    "data_nonmember_target = subset_to_tensor(data_nonmember_target)\n",
    "data_eval_attack = subset_to_tensor(data_eval_attack)\n",
    "\n",
    "# Create labels for training of attack model\n",
    "label_train_attack = torch.cat(\n",
    "    (torch.ones(len(data_train_shadow)), torch.zeros(len(data_out_shadow))), dim=0\n",
    ")\n",
    "data_train_attack = TransformedTensorDataset(\n",
    "    data_train_attack.tensors[0], label_train_attack, transform=transform\n",
    ")\n",
    "\n",
    "# create labels for evaluating the attack model\n",
    "label_eval_attack = torch.cat(\n",
    "    (torch.ones(len(data_train_target)), torch.zeros(len(data_nonmember_target))), dim=0\n",
    ")\n",
    "data_eval_attack = TransformedTensorDataset(\n",
    "    data_eval_attack.tensors[0], label_eval_attack, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "loader_train_shadow = DataLoader(data_train_shadow, batch_size=64, shuffle=True)\n",
    "loader_out_shadow = DataLoader(data_out_shadow, batch_size=64, shuffle=True)\n",
    "loader_train_attack = DataLoader(data_train_attack, batch_size=64, shuffle=True)\n",
    "loader_train_target = DataLoader(data_train_target, batch_size=64, shuffle=True)\n",
    "loader_nonmember_target = DataLoader(data_nonmember_target, batch_size=64, shuffle=True)\n",
    "loader_eval_attack = DataLoader(data_eval_attack, batch_size=64, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "target_model = CNN().to(device)\n",
    "shadow_model = CNN().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "optimizer_target = torch.optim.Adam(target_model.parameters(), lr=0.001)\n",
    "loss = 999\n",
    "for epoch in range(num_epochs_target):\n",
    "    print(f\"epoch {epoch}/{num_epochs_target} loss={loss}\")\n",
    "    loss = 0\n",
    "    for i, (images, labels) in tqdm(enumerate(loader_train_target)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs_target = target_model(images)\n",
    "        loss_target = F.nll_loss(outputs_target, labels)\n",
    "        optimizer_target.zero_grad()\n",
    "        loss_target.backward()\n",
    "        optimizer_target.step()\n",
    "        loss += loss_target\n",
    "target_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in loader_train_target:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        target = target_model(images)\n",
    "        _, prediction = torch.max(target, dim=1)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(f\"target model accu (train set): {correct}/{total}={correct/total*100:.2f}%\")\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in loader_nonmember_target:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        target = target_model(images)\n",
    "        _, prediction = torch.max(target, dim=1)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(f\"target model accu (test set): {correct}/{total}={correct/total*100:.2f}%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0/10 loss=999\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:04, 58.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1/10 loss=135.6267547607422\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 59.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2/10 loss=34.335731506347656\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:04, 58.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3/10 loss=23.78925323486328\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 60.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4/10 loss=17.746421813964844\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5/10 loss=14.4429349899292\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 59.88it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6/10 loss=11.743385314941406\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 60.17it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7/10 loss=10.147985458374023\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 60.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8/10 loss=7.657524585723877\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9/10 loss=6.925703048706055\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 60.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "target model accu (train set): 14938/15000=99.59%\n",
      "target model accu (test set): 14700/15000=98.00%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "optimizer_shadow = torch.optim.Adam(shadow_model.parameters(), lr=0.001)\n",
    "loss = 999\n",
    "for epoch in range(num_epochs_shadow):\n",
    "    print(f\"epoch {epoch}/{num_epochs_target} loss={loss}\")\n",
    "    loss = 0\n",
    "    for i, (images, labels) in tqdm(enumerate(loader_train_shadow)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs_shadow = shadow_model(images)\n",
    "        loss_shadow = F.nll_loss(outputs_shadow, labels)\n",
    "        optimizer_shadow.zero_grad()\n",
    "        loss_shadow.backward()\n",
    "        optimizer_shadow.step()\n",
    "        loss += loss_shadow\n",
    "shadow_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in loader_nonmember_target:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        target = shadow_model(images)\n",
    "        _, prediction = torch.max(target, dim=1)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    print(f\"shadow model accu: {correct}/{total}={correct/total*100:.2f}%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0/10 loss=999\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 60.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1/10 loss=142.8603973388672\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2/10 loss=37.368621826171875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 59.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3/10 loss=24.2596435546875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 60.82it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4/10 loss=19.069618225097656\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5/10 loss=15.747686386108398\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.16it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6/10 loss=12.181062698364258\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7/10 loss=10.698138236999512\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.67it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8/10 loss=9.221597671508789\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 61.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9/10 loss=8.278692245483398\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "235it [00:03, 59.47it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shadow model accu: 14654/15000=97.69%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class AttackModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttackModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "attack_model = AttackModel().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "optimizer_attack = torch.optim.Adam(attack_model.parameters(), lr=0.001)\n",
    "loss = 999\n",
    "for epoch in range(num_epochs_attack):\n",
    "    print(f\"epoch {epoch}/{num_epochs_attack}, loss={loss}\")\n",
    "    loss = 0\n",
    "    for idx, (images, labels) in tqdm(enumerate(loader_train_attack)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        posteriors_shadow = F.softmax(shadow_model(images), dim=1)\n",
    "        # print(posteriors_shadow)\n",
    "        top3_posteriors = torch.topk(posteriors_shadow, 3, dim=1)[0]\n",
    "        # print(top3_posteriors)\n",
    "        labels_attack = labels.float().unsqueeze(1)\n",
    "\n",
    "        # attack_outputs = attack_model(posteriors_shadow)\n",
    "        attack_outputs = attack_model(top3_posteriors)\n",
    "        loss_attack = F.binary_cross_entropy(attack_outputs, labels_attack)\n",
    "\n",
    "        optimizer_attack.zero_grad()\n",
    "        loss_attack.backward()\n",
    "        optimizer_attack.step()\n",
    "        loss += loss_attack"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0/20, loss=999\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 59.35it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1/20, loss=325.06988525390625\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:08, 58.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2/20, loss=324.98016357421875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.86it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 3/20, loss=324.8493347167969\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 59.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 4/20, loss=324.95257568359375\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.71it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 5/20, loss=324.9265441894531\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 61.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 6/20, loss=324.914794921875\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 59.89it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 7/20, loss=324.9212951660156\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 8/20, loss=324.87933349609375\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 59.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 9/20, loss=324.89532470703125\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:08, 57.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 10/20, loss=324.9516906738281\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.29it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 11/20, loss=324.8806457519531\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 12/20, loss=324.85443115234375\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.92it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 13/20, loss=324.8356628417969\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 14/20, loss=324.8828430175781\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 60.35it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 15/20, loss=324.91351318359375\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 61.37it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 16/20, loss=324.8971862792969\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 61.73it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 17/20, loss=324.84417724609375\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 61.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 18/20, loss=324.8438720703125\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 61.58it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 19/20, loss=324.8574523925781\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "469it [00:07, 61.96it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "attack_model.eval()\n",
    "total = 0\n",
    "\n",
    "all_pred = torch.empty((1))\n",
    "all_labels = torch.empty((1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (images, labels) in enumerate(loader_eval_attack):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        posteriors_target = F.softmax(target_model(images), dim=1)\n",
    "        top3_posteriors = torch.topk(posteriors_target, 3, dim=1)[0]\n",
    "\n",
    "        attack_outputs = attack_model(top3_posteriors)\n",
    "\n",
    "        all_pred = torch.cat((all_pred, attack_outputs.squeeze()), dim=0)\n",
    "        all_labels = torch.cat((all_labels, labels.squeeze()), dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for pred_thre in np.arange(0.30, 0.60, 0.02):\n",
    "    all_pred_bin = all_pred > pred_thre\n",
    "    all_labels_bin = all_labels > 0.5  # only 0 or 1\n",
    "\n",
    "    TP = (all_pred_bin & all_labels_bin).sum().item()\n",
    "    TN = ((~all_pred_bin) & (~all_labels_bin)).sum().item()\n",
    "    FP = (all_pred_bin & (~all_labels_bin)).sum().item()\n",
    "    FN = ((~all_pred_bin) & all_labels_bin).sum().item()\n",
    "\n",
    "    print(\n",
    "        f\"Attack Model Accuracy for thre={pred_thre:.2f} TP={TP} TN={TN} FP={FP} FN={FN} \",\n",
    "        end=\"\",\n",
    "    )\n",
    "    if (TP + FP) == 0 or (TP + FN) == 0:\n",
    "        print(\"metrics invalid\")\n",
    "        continue\n",
    "    accu = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"accu={accu:.2f} \" f\"prec={precision:.2f} recall={recall:.2f} f1={f1:.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attack Model Accuracy for thre=0.30 TP=14999 TN=9 FP=14992 FN=1 accu=0.50 prec=0.50 recall=1.00 f1=0.67\n",
      "Attack Model Accuracy for thre=0.32 TP=14995 TN=19 FP=14982 FN=5 accu=0.50 prec=0.50 recall=1.00 f1=0.67\n",
      "Attack Model Accuracy for thre=0.34 TP=14986 TN=29 FP=14972 FN=14 accu=0.50 prec=0.50 recall=1.00 f1=0.67\n",
      "Attack Model Accuracy for thre=0.36 TP=14975 TN=51 FP=14950 FN=25 accu=0.50 prec=0.50 recall=1.00 f1=0.67\n",
      "Attack Model Accuracy for thre=0.38 TP=14961 TN=92 FP=14909 FN=39 accu=0.50 prec=0.50 recall=1.00 f1=0.67\n",
      "Attack Model Accuracy for thre=0.40 TP=14919 TN=169 FP=14832 FN=81 accu=0.50 prec=0.50 recall=0.99 f1=0.67\n",
      "Attack Model Accuracy for thre=0.42 TP=14863 TN=275 FP=14726 FN=137 accu=0.50 prec=0.50 recall=0.99 f1=0.67\n",
      "Attack Model Accuracy for thre=0.44 TP=14807 TN=401 FP=14600 FN=193 accu=0.51 prec=0.50 recall=0.99 f1=0.67\n",
      "Attack Model Accuracy for thre=0.46 TP=14696 TN=511 FP=14490 FN=304 accu=0.51 prec=0.50 recall=0.98 f1=0.67\n",
      "Attack Model Accuracy for thre=0.48 TP=14546 TN=690 FP=14311 FN=454 accu=0.51 prec=0.50 recall=0.97 f1=0.66\n",
      "Attack Model Accuracy for thre=0.50 TP=13984 TN=1198 FP=13803 FN=1016 accu=0.51 prec=0.50 recall=0.93 f1=0.65\n",
      "Attack Model Accuracy for thre=0.52 TP=0 TN=15001 FP=0 FN=15000 metrics invalid\n",
      "Attack Model Accuracy for thre=0.54 TP=0 TN=15001 FP=0 FN=15000 metrics invalid\n",
      "Attack Model Accuracy for thre=0.56 TP=0 TN=15001 FP=0 FN=15000 metrics invalid\n",
      "Attack Model Accuracy for thre=0.58 TP=0 TN=15001 FP=0 FN=15000 metrics invalid\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}